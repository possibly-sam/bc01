---
title: "bc02"
author: "Phillip Abbott"
date: "Tue 24 Sep XIX"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```



```{r}


library(tidyverse)



library(tidytext)
library(tm)
library(e1071)
library(odbc)

library(NLP)
# library(openNLP)

library(odbc)

con <- dbConnect(odbc::odbc(), .connection_string = "Driver={PostgreSQL Unicode};Server=mcfc01.c4hbjfyzingo.eu-west-2.rds.amazonaws.com;Database=mcfc01;UID=mcfcuser01;PWD=projecthack01")


# con <- dbConnect(odbc::odbc(), .connection_string = "Driver={PostgreSQL Unicode};Database=usit_alpha")


```



```{sql connection=con,  output.var="business_cases_year_17"}

SELECT "Brief_Summary" ::varchar(4096), 
  uui01::bigint*1000000000+uui02 AS uui, 
  
  "CIO_Evaluation_Color" from public.business_case_alpha WHERE year=17

```

```{r}

# stringi::stri_length(business_cases_year_17[,1])

stringi::stri_length(business_cases_year_17[,1]) %>% max()
```

## Load the result

```{r}

source("pcx01.R")


load("p0.RData")



```

# no visible clustering from the first 2 components


```{r}


the_categories <- rep(1, nrow(business_cases_year_17))
the_categories[ business_cases_year_17$CIO_Evaluation_Color=="Yellow"] <- 2
the_categories[ business_cases_year_17$CIO_Evaluation_Color=="Red"] <- 2


p1 <- p0$my_projection_matrix[,1:3] %>% cbind(the_categories)
# p1 %>% head()

# (p1$idx - p1$uui) %>% min()

plot(p1$pcx_2~p1$pcx_1, col=p1$the_categories)

```

# can we find a correlation?

I did a naive logistic regression on 'gre          en or not' against the first few dozen principal components, a few at a time.  I threw out all the variables that R didn't show as significant with at least a '.'.  This is the list I was left with.  The next question is:  how good is this model, in terms of the ROC curve?  Can we improve it by taking out terms or adding other information (e.g. department).  To answer that question, one needs to calculate the ROC curve, which involves evaluating the prediction at different levels of probability.

```{r}

some_nice_pcx <- c(1,2,4,5, 9, 11, 18, 25, 33, 40, 48, 58, 60, 73, 76, 79, 95, 96, 97, 115, 116, 118)
p2 <- p0$my_projection_matrix[,(some_nice_pcx+1)] %>% cbind(the_categories)

p2$the_categories <- p2$the_categories  - 1 

hm <- glm(the_categories~., data=p2, family=binomial)

summary(hm)

```



```{r}

  
  

```





```{r}


  test_model <- function(the_formula, the_data, the_proportion) {
    result <- new.env(emptyenv())
    
    n <- the_data %>% nrow()
    
    result$tr <- sample(1:n, floor(the_proportion*n) )
    result$train <- the_data[result$tr,]
    result$test <- the_data[-result$tr,]
    
    result$hm <- glm(the_formula, data=result$train, family=binomial)
    
    result$pred <- predict(result$hm, result$test, type="response")
    result$test <- result$test %>% cbind( pred=result$pred ) 
      
    # result$table <- table(pred=predict(result$hm, test)$class, true=the_data$the_categories[-tr])
    # rresult$roc <- some_table_information(rresult$table)
    result
  }

t0 <- test_model(the_categories~., p2, 0.9)
t1 <- t0$test[,c("the_categories", "pred")]
colnames(t1) <- c("cat", "pred")


happy <- t1[t1$cat==0, "pred"]
sad <- t1[t1$cat==1, "pred"]

boxplot(pred~cat, data=t1)

happy %>% summary()
sad %>% summary()


```


so, given a column of category, and a column of probabilties, and a probability cutoff, classify the probabilities according to the cutoff

```{r}




some_table_information <- function(the_table) {
  
  result <- new.env(emptyenv())

  the_table_ <- the_table %>% as.data.frame()
  the_table_$actual <- the_table_$actual %>% as.character() %>% as.numeric() 
  the_table_$predicted <- the_table_$predicted  %>% as.logical() %>% as.numeric()
  result$the_table_ <- the_table_
  
  result$true_positive <- the_table_[ the_table_$actual==1 & the_table_$predicted==1, "Freq"]
  result$true_negative <- the_table_[ the_table_$actual==0 & the_table_$predicted==0, "Freq"]
  result$false_positive <- the_table_[ the_table_$actual==0 & the_table_$predicted==1, "Freq"]
  result$false_negative <- the_table_[ the_table_$actual==1 & the_table_$predicted==0, "Freq"]
  
  if (0 == result$true_positive %>% length() ) result$true_positive <- 0
  if (0 == result$true_negative %>% length() ) result$true_negative <- 0
  if (0 == result$false_positive %>% length() ) result$false_positive <- 0
  if (0 == result$false_negative %>% length() ) result$false_negative <- 0
  
  result$positive <- result$true_positive + result$false_negative
  result$negative <- result$true_negative + result$false_positive
  
  result$true_positive_rate <- result$true_positive/result$positive 
  result$false_positive_rate <- result$false_positive/result$negative 

  result$roc <- c(false_positive_rate=result$false_positive_rate, true_positive_rate=result$true_positive_rate )  
  
  
  result

}


tue <- function(the_categories, the_probabilities, the_cutoff) {
  
  result <- new.env(emptyenv())
  
  result$df <- data.frame(actual=the_categories, the_probabilities) %>% cbind( predicted=the_cutoff<  the_probabilities)
  
  result$tbl <- table(actual=result$df$actual, predicted=result$df$predicted)
  result$roc <- some_table_information( result$tbl )
  
  
  result
  
}

x0 <- tue( t1$cat, t1$pred, .5)

# x0$df %>% View()

x0$tbl
x0$roc$roc

```

```{r}

the_categories <- t1$cat
the_probabilities <- t1$pred
the_cutoff <- .5

tue0 <- function(the_categories, the_probabilities) {

  result <- new.env(emptyenv())
  
  result$get <- function(the_cutoff) {
    temp_ <- tue(the_categories, the_probabilities, the_cutoff)
    temp_$roc$roc
  }
  
  result$df <- data.frame(t(result$get(0)))
 for (k in 1:100) {
    result$df <- result$df %>% rbind(t(result$get(k/100))  )
 }
  
  
  result
}
  
x0 <- tue0( t1$cat, t1$pred)

# x0$df %>% View()

plot(true_positive_rate~false_positive_rate, data=x0$df)
abline(0,1)

rm(the_categories)
rm(the_probabilities)
rm(the_cutoff)



```


```{r}
roc01 <- x0$df[order(x0$df$false_positive_rate),]
auc <- 0
for (k in 2:nrow(roc01)) {
    x_0 <- roc01[k-1, "false_positive_rate"] 
    x_1 <- roc01[k, "false_positive_rate"] 
    y_1 <- roc01[k, "true_positive_rate"] 
    auc <- auc + y_1*(x_1-x_0)
}

auc


```










```{r}



  
  
t0 <- test_model(the_categories~., p2, 0.9)
t0$hm %>% summary()
t0$pred
t0$test

boxplot(t0$pred~t0$test$the_categories)

# given pred, I should be able to get an ROC

monday <- function(pred, test, cutoff) {
  
  r0 <- predict(pred, test) 
  r1 <- r0 < cutoff
  r1
}

monday(t0$hm, t0$test, .5)



```









```{r}


p0$my_principal_component_matrix %>% summary()
```


```{r}

cats <- MASS::cats

caTools::colAUC(t1$cat, t1$pred, plotROC=TRUE) 


```








